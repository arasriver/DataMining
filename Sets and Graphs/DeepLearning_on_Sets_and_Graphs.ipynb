{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# g(x) = +1 if there are distinct i,j,k in {1,...,10} with x[i]+x[j]+x[k] = 5, else -1"
      ],
      "metadata": {
        "id": "zc7mEP9WVTc5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ptmsIPwSi7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c955a8-eca3-4732-dd3e-7c0d0ab9820d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: [[3 9 4 ... 6 8 5]\n",
            " [3 0 6 ... 7 5 2]\n",
            " [6 9 3 ... 2 3 1]\n",
            " ...\n",
            " [4 8 5 ... 2 5 9]\n",
            " [4 5 2 ... 4 7 0]\n",
            " [4 5 7 ... 4 8 9]]\n",
            "Labels: [ 1  1  1 ... -1  1 -1]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "    # Define the ground truth function g\n",
        "def g_function(x):\n",
        "      n = len(x)\n",
        "      for i in range(n):\n",
        "          for j in range(i + 1, n):\n",
        "              for k in range(j + 1, n):\n",
        "                  if x[i] + x[j] + x[k] == 5:\n",
        "                      return 1\n",
        "      return -1\n",
        "\n",
        "def generate_dataset(num_samples, seed):\n",
        "    np.random.seed(seed)\n",
        "    # Generate random samples from {0, 1, ..., 9} for 10 components as question wanted\n",
        "    data = np.random.randint(0, 10, size=(num_samples, 10))\n",
        "    # Apply the function to each data point\n",
        "    labels = np.array([g_function(x) for x in data])\n",
        "    return data, labels\n",
        "\n",
        "# Generate dataset and assign to global variables\n",
        "data, labels = generate_dataset(num_samples=10000, seed=20)\n",
        "print(\"Data:\", data)\n",
        "print(\"Labels:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Statistics"
      ],
      "metadata": {
        "id": "nB-AhhvRVcrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_statistics(labels):\n",
        "    #Show classes statistics\n",
        "    classes, counts = np.unique(labels, return_counts=True)\n",
        "    stats = dict(zip(classes, counts))\n",
        "    return stats\n",
        "\n",
        "# Compute dataset statistics\n",
        "statistics = compute_statistics(labels)\n",
        "print(\"Dataset class balance:\", statistics)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=20)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape[0])\n",
        "print(\"Test set size:\", X_test.shape[0])\n",
        "print(\"Training set class balance:\", compute_statistics(y_train))\n",
        "print(\"Test set class balance:\", compute_statistics(y_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Vu9dXUVQqE",
        "outputId": "f01832bc-153e-451f-bcc0-382051b3c2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset class balance: {-1: 3540, 1: 6460}\n",
            "Training set size: 8000\n",
            "Test set size: 2000\n",
            "Training set class balance: {-1: 2853, 1: 5147}\n",
            "Test set class balance: {-1: 687, 1: 1313}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing permutaion sensitive NN"
      ],
      "metadata": {
        "id": "LEujKWD2RGsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model of NN"
      ],
      "metadata": {
        "id": "O6lu09ZS4n6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Define a neural network\n",
        "#Helpful link that I used: https://www.youtube.com/watch?v=kY14KfZQ1TI&t=8s\n",
        "class PermutationSensitiveNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim,hidden_dim2, output_dim):\n",
        "        super(PermutationSensitiveNN, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "J8cvR1ltRLKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare data for pytorch"
      ],
      "metadata": {
        "id": "rVjBLqWk43Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels from {-1, +1} to {0, 1}\n",
        "y_train = (y_train + 1) // 2\n",
        "y_test = (y_test + 1) // 2\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "9zsRtp1V42EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Initialize Parameters"
      ],
      "metadata": {
        "id": "VrooMGGP5SKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PermutationSensitiveNN(input_dim=10, hidden_dim=128, hidden_dim2=64, output_dim=1)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "fOsOgZTJ3wxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Evaluation"
      ],
      "metadata": {
        "id": "c6YndZYD5aLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs.squeeze() > 0).long()  # Convert logits to {0, 1}\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.long()).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/20], Loss: {avg_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdvdVfVa3A82",
        "outputId": "14660a5f-463b-407a-d5ab-67acea4009e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.4827, Test Accuracy: 0.8265\n",
            "Epoch [2/20], Loss: 0.4073, Test Accuracy: 0.8170\n",
            "Epoch [3/20], Loss: 0.3912, Test Accuracy: 0.8390\n",
            "Epoch [4/20], Loss: 0.3812, Test Accuracy: 0.8405\n",
            "Epoch [5/20], Loss: 0.3708, Test Accuracy: 0.8280\n",
            "Epoch [6/20], Loss: 0.3697, Test Accuracy: 0.8385\n",
            "Epoch [7/20], Loss: 0.3638, Test Accuracy: 0.8495\n",
            "Epoch [8/20], Loss: 0.3599, Test Accuracy: 0.8450\n",
            "Epoch [9/20], Loss: 0.3510, Test Accuracy: 0.8465\n",
            "Epoch [10/20], Loss: 0.3547, Test Accuracy: 0.8440\n",
            "Epoch [11/20], Loss: 0.3463, Test Accuracy: 0.8390\n",
            "Epoch [12/20], Loss: 0.3451, Test Accuracy: 0.8380\n",
            "Epoch [13/20], Loss: 0.3399, Test Accuracy: 0.8440\n",
            "Epoch [14/20], Loss: 0.3389, Test Accuracy: 0.8365\n",
            "Epoch [15/20], Loss: 0.3324, Test Accuracy: 0.8410\n",
            "Epoch [16/20], Loss: 0.3347, Test Accuracy: 0.8415\n",
            "Epoch [17/20], Loss: 0.3337, Test Accuracy: 0.8465\n",
            "Epoch [18/20], Loss: 0.3300, Test Accuracy: 0.8425\n",
            "Epoch [19/20], Loss: 0.3270, Test Accuracy: 0.8550\n",
            "Epoch [20/20], Loss: 0.3214, Test Accuracy: 0.8535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we want to test sensitivity of model\n",
        "# Example input\n",
        "original_input = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]], dtype=torch.float32)\n",
        "\n",
        "# Shuffle the input\n",
        "shuffled_input = original_input[:, torch.randperm(original_input.size(1))]\n",
        "\n",
        "# Model output for original and shuffled inputs\n",
        "model.eval()\n",
        "original_output = model(original_input)\n",
        "shuffled_output = model(shuffled_input)\n",
        "\n",
        "print(\"Original Input:\", original_input)\n",
        "print(\"Shuffled Input:\", shuffled_input)\n",
        "print(\"Original Output:\", original_output.item())\n",
        "print(\"Shuffled Output:\", shuffled_output.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX8DcxD_BqKZ",
        "outputId": "21b3752a-2752-473d-e5a0-c6ec637ac48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9., 0.]])\n",
            "Shuffled Input: tensor([[9., 1., 3., 6., 0., 4., 7., 8., 2., 5.]])\n",
            "Original Output: 2.379833698272705\n",
            "Shuffled Output: 1.1561832427978516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing of permutation invariant NN"
      ],
      "metadata": {
        "id": "oAwSBFe0RMw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#Deep Sets model\n",
        "#Helpful link that I used: https://jduarte.physics.ucsd.edu/iaifi-summer-school/1.3_deep_sets.html\n",
        "class DeepSets(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(DeepSets, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "\n",
        "        #phi, Processes each element of the input individually\n",
        "        self.phi = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # rho, Processes the pooled output\n",
        "        self.rho = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Applying phi to each component, then sum operation and rho\n",
        "        phi_output = self.phi(x)\n",
        "\n",
        "        pooled_output = torch.sum(phi_output, dim=1)\n",
        "\n",
        "        output = self.rho(pooled_output)\n",
        "        return output\n",
        "\n",
        "# Convert labels from {-1, +1} to {0, 1}\n",
        "y_train = (y_train + 1) // 2\n",
        "y_test = (y_test + 1) // 2\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "#Deep Sets model\n",
        "model = DeepSets(input_dim=1, hidden_dim=128, output_dim=1)\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary classification loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Reshape inputs to process each element individually\n",
        "        inputs = inputs.view(-1, 10, 1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.view(-1, 10, 1)\n",
        "            outputs = model(inputs)\n",
        "            predicted = (outputs.squeeze() > 0).long()  # Convert logits to {0, 1}\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels.long()).sum().item()\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/20], Loss: {avg_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BDXImGFjdEs",
        "outputId": "1beec984-eec9-4adb-a1d6-01eb6e2d9a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 0.4665, Test Accuracy: 0.8430\n",
            "Epoch [2/20], Loss: 0.3693, Test Accuracy: 0.8640\n",
            "Epoch [3/20], Loss: 0.3536, Test Accuracy: 0.8605\n",
            "Epoch [4/20], Loss: 0.3369, Test Accuracy: 0.8720\n",
            "Epoch [5/20], Loss: 0.3319, Test Accuracy: 0.8465\n",
            "Epoch [6/20], Loss: 0.3133, Test Accuracy: 0.8795\n",
            "Epoch [7/20], Loss: 0.3020, Test Accuracy: 0.8905\n",
            "Epoch [8/20], Loss: 0.2829, Test Accuracy: 0.8960\n",
            "Epoch [9/20], Loss: 0.2791, Test Accuracy: 0.8965\n",
            "Epoch [10/20], Loss: 0.2782, Test Accuracy: 0.8970\n",
            "Epoch [11/20], Loss: 0.2734, Test Accuracy: 0.8990\n",
            "Epoch [12/20], Loss: 0.2681, Test Accuracy: 0.8940\n",
            "Epoch [13/20], Loss: 0.2671, Test Accuracy: 0.8965\n",
            "Epoch [14/20], Loss: 0.2657, Test Accuracy: 0.8970\n",
            "Epoch [15/20], Loss: 0.2644, Test Accuracy: 0.8995\n",
            "Epoch [16/20], Loss: 0.2574, Test Accuracy: 0.9045\n",
            "Epoch [17/20], Loss: 0.2556, Test Accuracy: 0.9055\n",
            "Epoch [18/20], Loss: 0.2576, Test Accuracy: 0.9030\n",
            "Epoch [19/20], Loss: 0.2435, Test Accuracy: 0.9095\n",
            "Epoch [20/20], Loss: 0.2401, Test Accuracy: 0.9090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test for permutation-invariance\n",
        "original_input = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 0]], dtype=torch.float32).view(1, 10, 1)\n",
        "shuffled_input = original_input[:, torch.randperm(original_input.size(1)), :]\n",
        "\n",
        "model.eval()\n",
        "original_output = model(original_input)\n",
        "shuffled_output = model(shuffled_input)\n",
        "\n",
        "print(\"Original Input:\", original_input)\n",
        "print(\"Shuffled Input:\", shuffled_input)\n",
        "print(\"Original Output:\", original_output.item())\n",
        "print(\"Shuffled Output:\", shuffled_output.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUBDMEcfgFf_",
        "outputId": "c543fa68-048c-4947-cb1b-f7d04c471b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Input: tensor([[[1.],\n",
            "         [2.],\n",
            "         [3.],\n",
            "         [4.],\n",
            "         [5.],\n",
            "         [6.],\n",
            "         [7.],\n",
            "         [8.],\n",
            "         [9.],\n",
            "         [0.]]])\n",
            "Shuffled Input: tensor([[[8.],\n",
            "         [2.],\n",
            "         [3.],\n",
            "         [4.],\n",
            "         [5.],\n",
            "         [6.],\n",
            "         [9.],\n",
            "         [1.],\n",
            "         [0.],\n",
            "         [7.]]])\n",
            "Original Output: -12.324579238891602\n",
            "Shuffled Output: -12.324580192565918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cAdKngTzjlSL"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}